{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c88342c-bd45-497f-9600-7f0b6b50f2da",
   "metadata": {},
   "source": [
    "# Syllabus: Practical Reinforcement Learning Course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bc874a-74dd-4d77-bf44-dc97ff213e18",
   "metadata": {},
   "source": [
    "## Topics\n",
    "- Reinforcement Learning concepts and limitations\n",
    "- Reward function design and shaping\n",
    "- Hyperparameter tuning\n",
    "- Application of a trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3825098d-66d6-43ec-bc39-3b2a828bd1e8",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "In this course, you will learn how to:\n",
    "- Set up an RL simulation environment\n",
    "- Learn the terminology of reinforcement learning\n",
    "- Learn the importance of the reward function for model quality and fast training\n",
    "- Learn to modify critical parts of the algorithm, including the reward function\n",
    "- Practice thinking creatively to improve learning and reduce learning time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef01a75-e5d7-426f-82c1-6a5ab4c06020",
   "metadata": {},
   "source": [
    "## Pre-course Reading on OpenAI-Spinning Up\n",
    "- [RL Intro Part 1](https://spinningup.openai.com/en/latest/spinningup/rl_intro.html)\n",
    "- [RL Intro Part 2](https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html) (skip “What to learn in model-based RL”)\n",
    "- This is the algorithm that our preferred algorithm (TD3) is based on: [DDPG](https://spinningup.openai.com/en/latest/algorithms/ddpg.html) (read just the background)\n",
    "- This describes our preferred algorithm: [TD3](https://spinningup.openai.com/en/latest/algorithms/td3.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72870ffe-9ebb-42d4-b73d-e443f1ace2ea",
   "metadata": {},
   "source": [
    "## Course Design\n",
    "- Day 1, Part A: Introduction to reinforcement learning and research environments\n",
    "- Day 1, Part B: More on Reward Design\n",
    "- Day 1, Part C: Faster Learning\n",
    "- Day 1, Part D: Parking a Car with RL\n",
    "- Day 2, Part A: Learning To Run\n",
    "- Day 2, Part B: TD3 Algorithm\n",
    "- Day 3, Part A: Modifying The Environment\n",
    "- Day 3, Part B: Reward Shaping, Generalization\n",
    "- Day 4, Part A: Hyperparameter Tuning\n",
    "- Day 4, Part B: Creating Custom Environments\n",
    "- Day 5: Model implementation and multi-agent modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c47d90a-976b-4c4c-83f8-ec2d30e7a850",
   "metadata": {},
   "source": [
    "## Technical Requirements\n",
    "- At least a 4-core laptop\n",
    "- Some Python experience\n",
    "- Some git experience"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
