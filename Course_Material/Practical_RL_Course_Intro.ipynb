{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c88342c-bd45-497f-9600-7f0b6b50f2da",
   "metadata": {},
   "source": [
    "# Syllabus: Practical Reinforcement Learning Course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8baaba-327e-4571-a870-76b46fe648c8",
   "metadata": {},
   "source": [
    "This is a short course for data scientists and other practitioners that introduces the practical considerations needed to effectively apply reinforcement learning to real-world problems.  The course uses a simulation environment (Robot Ant) that simplifies some aspects of implementation but addresses real, Physics-based learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bc874a-74dd-4d77-bf44-dc97ff213e18",
   "metadata": {},
   "source": [
    "## Topics\n",
    "- Reinforcement Learning concepts and limitations\n",
    "- Reward function design and shaping\n",
    "- Hyperparameter tuning\n",
    "- Application of a trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3825098d-66d6-43ec-bc39-3b2a828bd1e8",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "In this course, you will learn how to:\n",
    "- Set up an RL simulation environment\n",
    "- Learn the terminology of reinforcement learning\n",
    "- Learn the importance of the reward function for model quality and fast training\n",
    "- Learn to modify critical parts of the algorithm, including the reward function\n",
    "- Practice thinking creatively to improve learning and reduce learning time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef01a75-e5d7-426f-82c1-6a5ab4c06020",
   "metadata": {},
   "source": [
    "## Pre-course Reading on OpenAI-Spinning Up\n",
    "- [RL Intro Part 1](https://spinningup.openai.com/en/latest/spinningup/rl_intro.html)\n",
    "- [RL Intro Part 2](https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html) (skip “What to learn in model-based RL”)\n",
    "- This is the algorithm that our preferred algorithm (TD3) is based on: [DDPG](https://spinningup.openai.com/en/latest/algorithms/ddpg.html) (read just the background)\n",
    "- This describes our preferred algorithm: [TD3](https://spinningup.openai.com/en/latest/algorithms/td3.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72870ffe-9ebb-42d4-b73d-e443f1ace2ea",
   "metadata": {},
   "source": [
    "## Course Design\n",
    "- Day 1, Part A: Introduction to reinforcement learning and research environments\n",
    "- Day 1, Part B: More on Reward Design\n",
    "- Day 1, Part C: Faster Learning\n",
    "- Day 1, Part D: Parking a Car with RL\n",
    "- Day 2, Part A: Learning To Run\n",
    "- Day 2, Part B: TD3 Algorithm\n",
    "- Day 3, Part A: Modifying The Environment\n",
    "- Day 3, Part B: Reward Shaping, Generalization\n",
    "- Day 4, Part A: Hyperparameter Tuning\n",
    "- Day 4, Part B: Creating Custom Environments\n",
    "- Day 5, Part A: Multi-Agent RL\n",
    "- Day 5, Part B: Using Your Trained Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c47d90a-976b-4c4c-83f8-ec2d30e7a850",
   "metadata": {},
   "source": [
    "## Technical Requirements\n",
    "- At least a 4-core computer\n",
    "- Some experience with git, Python, and Jupyter notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a66da-7e97-48c5-8320-80d67f59748b",
   "metadata": {},
   "source": [
    "## Setup\n",
    "1. If you don't have conda installed, install it so that you can create the environment.  We like to use [Miniconda](https://docs.conda.io/en/latest/miniconda.html) instead of [Anaconda](https://docs.anaconda.com/anaconda/install/), but either will work well.  See the [conda user guide](https://conda.io/projects/conda/en/latest/user-guide/getting-started.html) for help getting up and running.\n",
    "2. Pull this repo using your favorite method (ssh, html), such as\n",
    "\n",
    "```bash\n",
    "git clone git@github.com:Quansight/Practical-RL.git\n",
    "```\n",
    "\n",
    "3. Go to the Practial-RL directory\n",
    "\n",
    "```bash\n",
    "cd Practical-RL\n",
    "```\n",
    "\n",
    "4. Build the environment (see the [conda user guide](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html) for more on building environments)\n",
    "\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "    \n",
    "5. Activate the newly created environment, `TD3` (see the conda user guide for help)\n",
    "\n",
    "```bash\n",
    "activate TD3\n",
    "```\n",
    "    \n",
    "6. Start JupyterLab and open the first notebook, `Day1_PartA.ipynb`, in the Course_Material folder\n",
    "    \n",
    "```bash\n",
    "jupyter lab\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
