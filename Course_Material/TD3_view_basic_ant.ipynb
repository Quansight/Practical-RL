{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90b777-e7f5-464e-b2dd-c62271c647c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This can leave open processes if you don't keep track of them, be sure to clean up after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e4534-ea28-4c90-b6ca-23d768c7aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gym\n",
    "import pybullet_envs\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "import utils\n",
    "import TD3\n",
    "from numpngw import write_apng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef00479-40b0-4570-a8d4-bd404f53cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def eval_policy_render(policy, env_name, seed, eval_episodes=1):\n",
    "    eval_env = gym.make(env_name, render=True)\n",
    "    eval_env.seed(seed + 100)\n",
    "\n",
    "    avg_reward = 0.\n",
    "    for i in range(eval_episodes):\n",
    "        eval_env.robot.walk_target_x = 1000  \n",
    "        eval_env.robot.walk_target_y = 0\n",
    "        state, done = eval_env.reset(), False\n",
    "        images = [eval_env.render('rgb_array')]\n",
    "        while not done:\n",
    "            time.sleep(1. / 60.)\n",
    "            action = policy.select_action(np.array(state))\n",
    "            state, reward, done, _ = eval_env.step(action)\n",
    "            avg_reward += reward\n",
    "            images.append(eval_env.render('rgb_array'))\n",
    "\n",
    "        print(f'Saving animation: anim_{i}.png, length: {len(images)} frames.')\n",
    "        write_apng(f'anim_{i}.png', images[::2], delay=50)\n",
    "        print('Save file complete')\n",
    "            \n",
    "    avg_reward /= eval_episodes\n",
    "    return avg_reward\n",
    "\n",
    "def load_policy(env_name_var):\n",
    "    args = {\n",
    "            \"policy\" : \"TD3\",                  # Policy name (TD3, DDPG or OurDDPG)\n",
    "            \"env\" : env_name_var,       # OpenAI gym environment name\n",
    "            \"seed\" : 0,                        # Sets Gym, PyTorch and Numpy seeds\n",
    "            \"start_timesteps\" : 25e3,          # Time steps initial random policy is used\n",
    "            \"eval_freq\" : 5e3,                 # How often (time steps) we evaluate\n",
    "            \"max_timesteps\" : 1.5e6,             # Max time steps to run environment\n",
    "            \"expl_noise\" : 0.1,                # Std of Gaussian exploration noise\n",
    "            \"batch_size\" : 256,                # Batch size for both actor and critic\n",
    "            \"discount\" : 0.99,                 # Discount factor\n",
    "            \"tau\" : 0.005,                     # Target network update rate\n",
    "            \"policy_noise\" : 0.2,              # Noise added to target policy during critic update\n",
    "            \"noise_clip\" : 0.5,                # Range to clip target policy noise\n",
    "            \"policy_freq\" : 2,                 # Frequency of delayed policy updates\n",
    "            \"save_model\" : \"store_true\",       # Save model and optimizer parameters\n",
    "            \"load_model\" : \"default\",          # Model load file name, \"\" doesn't load, \"default\" uses file_name\n",
    "           }\n",
    "\n",
    "    file_name = f\"{args['policy']}_{args['env']}_{args['seed']}\"\n",
    "    print(\"---------------------------------------\")\n",
    "    print(f\"Policy: {args['policy']}, Env: {args['env']}, Seed: {args['seed']}\")\n",
    "    print(\"---------------------------------------\")\n",
    "\n",
    "    if not os.path.exists(\"./results\"):\n",
    "        os.makedirs(\"./results\")\n",
    "\n",
    "    if args['save_model'] and not os.path.exists(\"./models\"):\n",
    "        os.makedirs(\"./models\")\n",
    "\n",
    "    env = gym.make(args['env'])\n",
    "\n",
    "    # Set seeds\n",
    "    env.seed(args['seed'])\n",
    "    env.action_space.seed(args['seed'])\n",
    "    torch.manual_seed(args['seed'])\n",
    "    np.random.seed(args['seed'])\n",
    "\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.shape[0] \n",
    "    max_action = float(env.action_space.high[0])\n",
    "\n",
    "    kwargs = {\n",
    "        \"state_dim\": state_dim,\n",
    "        \"action_dim\": action_dim,\n",
    "        \"max_action\": max_action,\n",
    "        \"discount\": args['discount'],\n",
    "        \"tau\": args['tau'],\n",
    "    }\n",
    "\n",
    "    # Initialize policy\n",
    "    if args['policy'] == \"TD3\":\n",
    "        # Target policy smoothing is scaled wrt the action scale\n",
    "        kwargs[\"policy_noise\"] = args['policy_noise'] * max_action\n",
    "        kwargs[\"noise_clip\"] = args['noise_clip'] * max_action\n",
    "        kwargs[\"policy_freq\"] = args['policy_freq']\n",
    "        policy = TD3.TD3(**kwargs)\n",
    "\n",
    "    if args['load_model'] != \"\":\n",
    "        policy_file = file_name if args['load_model'] == \"default\" else args['load_model']\n",
    "        policy.load(f\"./models/{policy_file}\")\n",
    "\n",
    "    return policy\n",
    "\n",
    "#eval_policy_render(policy, \"MyAntBulletEnv-v0\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a26c2db-f9fa-41df-a48f-9013fb2fa7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run to here to eval/render animations\n",
    "policy = load_policy(\"AntBulletEnv-v0\")\n",
    "eval_policy_render(policy, \"AntBulletEnv-v0\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e46cbe-2c59-4272-b944-e5ab27ebc692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
